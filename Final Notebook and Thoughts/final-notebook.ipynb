{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90860,"databundleVersionId":10740331,"sourceType":"competition"},{"sourceId":2474164,"sourceType":"datasetVersion","datasetId":1496720},{"sourceId":3952946,"sourceType":"datasetVersion","datasetId":1554380},{"sourceId":10442838,"sourceType":"datasetVersion","datasetId":6463679}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing and explaining modules","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\n#These are basic library so no need for explaination","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications.densenet import preprocess_input\nfrom keras.layers import Input\nfrom tensorflow.keras.optimizers import Adam\n#This is done to make the model making process smoother nothing else ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import cv2 \n#This library will help in reading image pixels ,manipulating pixels etc. ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pathlib\n#This library will help in gathering data , will elaborate later. ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os \n#This library will help in intraction of notebook with storage , so this will help us to import data. ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir=\"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train\"\ndata_dir=pathlib.Path(data_dir)\ndata_dir\n#As you can see data_dir has now been converted to a posixpath object which is better for us than simple string str path before \n#This is will help us later for categorization by the use of pathlib library ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"list(data_dir.glob('*/*.jpg'))[:5]\n#As you can see glob function has helped us to categorize all files with \".jpg\" in train directory\n#'*/*' will help us in getting all files with .jpg in it and here */* used when the files are in subdirectory of the directory whoes path is given.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing of Data","metadata":{}},{"cell_type":"code","source":"#As the folders are a lot and writting them with brute force will take a lot of time so we will make a for loop containing name of all folders but first we have to make a list with all folder names \nfolder_names = [item.name for item in data_dir.iterdir() if item.is_dir()]\n#item.name will give the item's name \n#data_dir.iterdir() will iterate over the directory with the path in data_dir which already contains the posixpath to train directory \n#\"if item.is_dir()\" will check if the item is directory or not \n\n# Print the folder names\nprint(folder_names)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#now we will create the dataset to be used for making a input array for our model\n# It will help us in mapping dataset of x and y later \nanimals_dataset={}\nfor i in folder_names:\n    if(\"+\" in i):#This is used to remove '+' sign in dataset to make it more readable\n        i_new=i.replace('+',' ')\n        animals_dataset[f\"{i_new}\"] = list(data_dir.glob(f'{i}/*'))\n    else:\n        animals_dataset[f\"{i}\"] = list(data_dir.glob(f'{i}/*')) \n#This set will help us later in creating x and y for training of model.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I have made sure that we make the dataset before adding the leftout classes in the training set as the training set in pixel play competition does not contain dataset of those classes. \n","metadata":{}},{"cell_type":"code","source":"#Now we will append remaining classes and also find out the leftout classes. \nremaining_classes=[]\nclass_path=\"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/classes.txt\"\n#As the text file related to the above path contains all the classes \nwith open(class_path, 'r') as file:\n    for line in file:\n        line=line.split()\n        if(line[1] in folder_names):#This make sures that the classes, which are already in folder_names, does not append again. \n            pass\n        else:\n            print(line[1])\n            extra.append(line[1])\n            folder_names.append(line[1])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Above shows all the leftout classes. ","metadata":{}},{"cell_type":"code","source":"leftout_dir=\"/kaggle/input/animal-image-dataset-90-different-animals/animals/animals\"\n#This path leads to dataset related to 7 out of 10 leftout classes. [horse,gorilla,fox,sheep,chimpanzee,squirrel,rhinoceros]\nleftout_dir=pathlib.Path(leftout_dir)#Just to convert into posixpath object\nfor i in extra:\n    temp=list(leftout_dir.glob(f'{i}/*'))\n    temp.extend(temp)\n    temp.extend(temp)#This causes the 7 leftout classes to have 240 images, which helps in data balancing.\n    animals_dataset[f'{i}']=temp\nrabbit_dir=\"/kaggle/input/cat-vs-rabbit/train-cat-rabbit/rabbit\"\nrabbit_dir=pathlib.Path(rabbit_dir)\nanimals_dataset['rabbit']=list(rabbit_dir.glob('*.jpg'))[:250]\nmoose_dir=\"/kaggle/input/moose-and-collie/Moose Data/train\"\nmoose_dir=pathlib.Path(moose_dir)\nanimals_dataset['moose']=list(moose_dir.glob('*.jpg'))[:250]\ncollie_dir=\"/kaggle/input/moose-and-collie/Collie Data/images.cv_xa14kcwlpkyeb4vprlojb/data/train/border_collie\"\ncollie_dir=pathlib.Path(collie_dir)\nanimals_dataset['collie']=list(collie_dir.glob('*.jpg'))[:250]\n#Here i have sliced the dataset to 250 and i think rest is self-explanatory.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img=cv2.imread('/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/train/antelope/00044.jpg')\nimg.shape\n#This will convert a img from its path to a 3d array that has his value of bgr color.\n#Here shape function gives the value of number of pixels in x,y and lastly 3 tells us that it contains different value of rgb combinations \n#This will help us to provide input to the model","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"animals_label=[]\nfor i in folder_names:\n    if('+' in i):\n        name_new=(i).replace('+',' ')\n        animals_label.append(name_new)\n        continue \n    else:\n        animals_label.append(i)\n#It will help in getting the name of animal related to the number and creating a y output array for x input array to train the model.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=[]\ny=[]\nfor i in animals_dataset:\n    for j in animals_dataset[i]:\n        img=cv2.imread(str(j))#Reading its bgr combination and converting it into a 3d array \n        img= cv2.resize(img ,(224,224))#As all the images have different size , we have to resize the image by cv2 library. \n        #Also i have resized to 224 by 224 as densenet base works best for 224 by 224 images.\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) #This helps in converting bgr to rgb and this is crucial becausing densenet is trained on rgb dataset\n        x.append(img)\n        y.append(animals_label.index(i))\n#Here we are making x and y where x contains the 3d array of its rgb combination and y contains its related number of its animal name .","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x=np.array(x)\ny=np.array(y)\n#Converting the list into numpy arrays as tensorflow takes arrays\nx = preprocess_input(x)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"# Load the DenseNet121 model\ndensenet_base = DenseNet121(\n    include_top=False,         # This is to exclude the dense network as we will be using our own dense network which is better.\n    weights='imagenet',        # This tells the pretrained model that we want weights that were pretrained on imagenet dataset.\n    input_shape=(224, 224, 3), # Shape of input images.\n    pooling='avg',             # Here it helps in reducing the computation and also to flatten the array to input in dense network.\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"densenet_base.trainable=False\nmodel = Sequential([\n  Input(shape=(224,224,3)),#Specifying the input shape\n  densenet_base , # Using densenet_base as a convolutional layer.\n  layers.Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)), #Here we used L2 regularization to reduce overfitting\n  layers.Dropout(0.5), #A dropout layer to reduce overfitting\n  layers.Dense(50, activation ='softmax') #A output array with probability of each class.\n])\n\nmodel.compile(optimizer=Adam(learning_rate=1e-4) , #Here we used adam optimizer and a lower learning to get a more accurate model\n              loss=\"sparse_categorical_crossentropy\", #self-explanatory\n              metrics=['accuracy']) #Metric used is accuracy to tackle underfitting.\nmodel.fit(x, y, epochs=20) \n#As this model is subject to change so i am not putting comments in it ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Making of csv file ","metadata":{}},{"cell_type":"code","source":"test_dir=pathlib.Path(\"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test\")\ntest_images = [item.name for item in test_dir.iterdir()]\ntest_images.sort()\ntesting=[]\nfor i in test_images:\n    arr=cv2.imread(f\"/kaggle/input/vlg-recruitment-24-challenge/vlg-dataset/vlg-dataset/test/{i}\")\n    arr = cv2.cvtColor(arr, cv2.COLOR_BGR2RGB)\n    arr=cv2.resize(arr,(224,224))\n    arr = preprocess_input(arr)\n    testing.append(arr)\ntesting=np.array(testing)\n#As explained before in preprocessing of x input , i prefer not to explain twice. ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions=model.predict(testing)\ncsv_class=[]\nfor i in range(len(test_images)):\n    csv_class.append(animals_label[np.argmax(predictions[i])])#It will help in getting the value with max probability.\ndf = pd.DataFrame({\n    \"image_id\": test_images ,\n    \"class\" : csv_class }  #Making of csv file\ndf.to_csv(\"predictions.csv\", index=False) \n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}