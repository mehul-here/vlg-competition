# Thoughts for 12th January

## Summary
Today, I focused on balancing the dataset, which led to a significant improvement in accuracy. This step was critical to ensuring the model performed well across all classes.

## Progress and Observations
1. **Dataset Imbalance Realization:**  
   - Noticed that the dataset was imbalanced, with some classes having significantly more images than others.

2. **Data Augmentation Decision:**  
   - Initially considered data augmentation to balance the dataset but recalled that it previously caused a decrease in accuracy.  
   - Decided to exclude this approach.

3. **Threshold for Images per Class:**  
   - Opted to set a threshold of **250 images per class**.  
   - This threshold was selected as a balanced number—not too high to cause RAM overflow and not too low to compromise the dataset's quality.

4. **Adjustments for Specific Classes:**  
   - **Collie, Rabbit, and Moose:** These datasets exceeded the 250-image threshold, so I sliced them accordingly.  
   - **Other Classes:** Extended their image lists repeatedly and then sliced them to reach the 250-image limit.

5. **Results:**  
   - The balancing process worked effectively.  
   - Achieved an accuracy of **73%**, which was far beyond expectations.  
   - Initially feared barely crossing 50%, especially since the competition description indicated that 50% was considered very good accuracy.

## Reflections
- Balancing the dataset was a critical step and proved to be the turning point in improving accuracy.  
- It’s gratifying to see such significant progress.


---

So final day is coming for this competition , huh 